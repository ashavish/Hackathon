{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv(\"data/Train.csv\")\n",
    "tags = pd.read_csv(\"data/Tags.csv\")\n",
    "test_data = pd.read_csv(\"data/Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_COLS = ['Computer Science','Mathematics','Physics','Statistics']\n",
    "TAGS = list(tags['Tags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['ABSTRACT'] = train_data['ABSTRACT'].str.lower()\n",
    "test_data['ABSTRACT'] = test_data['ABSTRACT'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "train_data['ABSTRACT'] = train_data['ABSTRACT'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "test_data['ABSTRACT'] = test_data['ABSTRACT'].str.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, val = train_test_split(train_data,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Get best threshold for each label\n",
    "def get_cut_offthreshold(y_pred_prob,validation_set,TAGS):\n",
    "    thresholds = np.array(list(range(0,100)))/100.0\n",
    "    best_thresholds = []\n",
    "    for idx in range(0,25):\n",
    "        scores = [f1_score(validation_set[TAGS[idx]], y_pred_prob[:,idx] > thresh, average='micro') for thresh in thresholds]\n",
    "        best_thresh = thresholds[np.argmax(scores)]\n",
    "        best_thresholds.append(best_thresh)\n",
    "    return best_thresholds\n",
    "\n",
    "# Get predictions based on probabilities and class specific thresholds\n",
    "def get_predictions(pred_prob,best_thresholds,TAGS):\n",
    "    predictions = np.zeros((pred_prob.shape[0],len(TAGS)))\n",
    "    for idx in range(0,25):\n",
    "        predictions[:,idx] = pred_prob[:,idx] > best_thresholds[idx]    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal Sentence Embedding with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "TF_MODULE_URL= \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "\n",
    "def universal_sent_embedding():\n",
    "    '''\n",
    "    Get the universal sentence encoder from TFHUB. Takes time to load, so invoke once\n",
    "    and use everywhere else.\n",
    "    '''\n",
    "    t_start = time.time()\n",
    "    # tf.disable_eager_execution()\n",
    "    # embed_ = hub.Module(cfg[\"TF_MODULE_URL\"])\n",
    "    embed_ = hub.load(TF_MODULE_URL)\n",
    "    t_end = time.time()\n",
    "    print(\"USE module loaded in {} secs\".format(str(t_end-t_start)))\n",
    "    return embed_\n",
    "\n",
    "\n",
    "def get_uni_sent_embedding(sents,embed):\n",
    "    '''\n",
    "    Get embeddings using the universal sentence encoder\n",
    "    '''  \n",
    "    t_start = time.time()\n",
    "    sent_embeddings = embed(sents)\n",
    "    # with tf.Session() as session:\n",
    "    #     session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    #     sent_embeddings = session.run(embed(sents))\n",
    "    print(\"Shape of sentence embeddings {0}\".format(str(sent_embeddings.shape)))\n",
    "    t_end = time.time()\n",
    "    return sent_embeddings\n",
    "\n",
    "def keras_use_embedding_model():\n",
    "    '''\n",
    "    Use universal sentence encoder in the embedding layer of a Keras model\n",
    "    '''    \n",
    "    embedding = TF_MODULE_URL\n",
    "    hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "                               dtype=tf.string, trainable=False)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(hub_layer)\n",
    "    model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(25,activation='sigmoid'))\n",
    "    print(model.summary())\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "        optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def keras_use_embedding_model_train(keras_model,train_sents,train_labels,test_sents,test_labels):\n",
    "    '''\n",
    "    Train the keras models. Change parameters here if needed\n",
    "    '''\n",
    "    n_epochs = 50\n",
    "    n_batch_size = 32\n",
    "    # session = tf.Session()\n",
    "    # tf.keras.backend.set_session(session)\n",
    "    # session.run(tf.global_variables_initializer())\n",
    "    # session.run(tf.tables_initializer())\n",
    "    history = keras_model.fit(train_sents,\n",
    "            train_labels,\n",
    "            validation_data=(test_sents, test_labels),\n",
    "            epochs=n_epochs,\n",
    "            batch_size=n_batch_size)\n",
    "    return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_1 (KerasLayer)   (None, 512)               256797824 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 25)                2525      \n",
      "=================================================================\n",
      "Total params: 256,851,649\n",
      "Trainable params: 53,825\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "351/351 [==============================] - 14s 38ms/step - loss: 0.2239 - accuracy: 0.1945 - val_loss: 0.1516 - val_accuracy: 0.3395\n",
      "Epoch 2/50\n",
      "351/351 [==============================] - 13s 38ms/step - loss: 0.1474 - accuracy: 0.3377 - val_loss: 0.1259 - val_accuracy: 0.4127\n",
      "Epoch 3/50\n",
      "351/351 [==============================] - 13s 37ms/step - loss: 0.1293 - accuracy: 0.3944 - val_loss: 0.1140 - val_accuracy: 0.4755\n",
      "Epoch 4/50\n",
      "351/351 [==============================] - 14s 41ms/step - loss: 0.1201 - accuracy: 0.4334 - val_loss: 0.1071 - val_accuracy: 0.4980\n",
      "Epoch 5/50\n",
      "351/351 [==============================] - 14s 40ms/step - loss: 0.1141 - accuracy: 0.4660 - val_loss: 0.1029 - val_accuracy: 0.5234\n",
      "Epoch 6/50\n",
      "351/351 [==============================] - 13s 38ms/step - loss: 0.1097 - accuracy: 0.4884 - val_loss: 0.0992 - val_accuracy: 0.5273\n",
      "Epoch 7/50\n",
      "351/351 [==============================] - 14s 39ms/step - loss: 0.1065 - accuracy: 0.4942 - val_loss: 0.0970 - val_accuracy: 0.5348\n",
      "Epoch 8/50\n",
      "351/351 [==============================] - 13s 38ms/step - loss: 0.1035 - accuracy: 0.5144 - val_loss: 0.0955 - val_accuracy: 0.5295\n",
      "Epoch 9/50\n",
      "351/351 [==============================] - 13s 38ms/step - loss: 0.1016 - accuracy: 0.5174 - val_loss: 0.0940 - val_accuracy: 0.5437\n",
      "Epoch 10/50\n",
      "351/351 [==============================] - 13s 38ms/step - loss: 0.0999 - accuracy: 0.5271 - val_loss: 0.0933 - val_accuracy: 0.5370\n",
      "Epoch 11/50\n",
      "351/351 [==============================] - 13s 38ms/step - loss: 0.0984 - accuracy: 0.5337 - val_loss: 0.0927 - val_accuracy: 0.5555\n",
      "Epoch 12/50\n",
      "351/351 [==============================] - 13s 38ms/step - loss: 0.0973 - accuracy: 0.5390 - val_loss: 0.0923 - val_accuracy: 0.5484\n",
      "Epoch 13/50\n",
      "351/351 [==============================] - 13s 38ms/step - loss: 0.0959 - accuracy: 0.5392 - val_loss: 0.0914 - val_accuracy: 0.5523\n",
      "Epoch 14/50\n",
      "351/351 [==============================] - 13s 38ms/step - loss: 0.0949 - accuracy: 0.5479 - val_loss: 0.0911 - val_accuracy: 0.5498\n",
      "Epoch 15/50\n",
      "351/351 [==============================] - 14s 38ms/step - loss: 0.0942 - accuracy: 0.5500 - val_loss: 0.0907 - val_accuracy: 0.5594\n",
      "Epoch 16/50\n",
      "351/351 [==============================] - 13s 38ms/step - loss: 0.0936 - accuracy: 0.5507 - val_loss: 0.0906 - val_accuracy: 0.5548\n",
      "Epoch 17/50\n",
      "351/351 [==============================] - 13s 38ms/step - loss: 0.0930 - accuracy: 0.5549 - val_loss: 0.0906 - val_accuracy: 0.5512\n",
      "Epoch 18/50\n",
      "351/351 [==============================] - 13s 38ms/step - loss: 0.0923 - accuracy: 0.5540 - val_loss: 0.0900 - val_accuracy: 0.5566\n",
      "Epoch 19/50\n",
      "351/351 [==============================] - 13s 38ms/step - loss: 0.0913 - accuracy: 0.5582 - val_loss: 0.0896 - val_accuracy: 0.5609\n",
      "Epoch 20/50\n",
      "351/351 [==============================] - 14s 39ms/step - loss: 0.0909 - accuracy: 0.5576 - val_loss: 0.0895 - val_accuracy: 0.5609\n",
      "Epoch 21/50\n",
      "351/351 [==============================] - 13s 38ms/step - loss: 0.0902 - accuracy: 0.5638 - val_loss: 0.0896 - val_accuracy: 0.5566\n",
      "Epoch 22/50\n",
      "351/351 [==============================] - 13s 38ms/step - loss: 0.0899 - accuracy: 0.5633 - val_loss: 0.0891 - val_accuracy: 0.5569\n",
      "Epoch 23/50\n",
      "351/351 [==============================] - 14s 39ms/step - loss: 0.0890 - accuracy: 0.5636 - val_loss: 0.0889 - val_accuracy: 0.5619\n",
      "Epoch 24/50\n",
      "351/351 [==============================] - 14s 39ms/step - loss: 0.0891 - accuracy: 0.5651 - val_loss: 0.0891 - val_accuracy: 0.5655\n",
      "Epoch 25/50\n",
      "351/351 [==============================] - 13s 38ms/step - loss: 0.0886 - accuracy: 0.5694 - val_loss: 0.0890 - val_accuracy: 0.5687\n",
      "Epoch 26/50\n",
      "351/351 [==============================] - 13s 38ms/step - loss: 0.0882 - accuracy: 0.5701 - val_loss: 0.0892 - val_accuracy: 0.5669\n",
      "Epoch 27/50\n",
      "351/351 [==============================] - 14s 39ms/step - loss: 0.0873 - accuracy: 0.5730 - val_loss: 0.0887 - val_accuracy: 0.5623\n",
      "Epoch 28/50\n",
      "351/351 [==============================] - 14s 38ms/step - loss: 0.0873 - accuracy: 0.5721 - val_loss: 0.0886 - val_accuracy: 0.5684\n",
      "Epoch 29/50\n",
      "351/351 [==============================] - 14s 38ms/step - loss: 0.0863 - accuracy: 0.5756 - val_loss: 0.0889 - val_accuracy: 0.5602\n",
      "Epoch 30/50\n",
      "351/351 [==============================] - 14s 39ms/step - loss: 0.0864 - accuracy: 0.5708 - val_loss: 0.0884 - val_accuracy: 0.5644\n",
      "Epoch 31/50\n",
      "351/351 [==============================] - 14s 40ms/step - loss: 0.0862 - accuracy: 0.5770 - val_loss: 0.0884 - val_accuracy: 0.5623\n",
      "Epoch 32/50\n",
      "351/351 [==============================] - 12s 35ms/step - loss: 0.0857 - accuracy: 0.5790 - val_loss: 0.0887 - val_accuracy: 0.5669\n",
      "Epoch 33/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0854 - accuracy: 0.5815 - val_loss: 0.0887 - val_accuracy: 0.5737\n",
      "Epoch 34/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0849 - accuracy: 0.5815 - val_loss: 0.0886 - val_accuracy: 0.5630\n",
      "Epoch 35/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0851 - accuracy: 0.5751 - val_loss: 0.0888 - val_accuracy: 0.5644\n",
      "Epoch 36/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0841 - accuracy: 0.5836 - val_loss: 0.0886 - val_accuracy: 0.5637\n",
      "Epoch 37/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0841 - accuracy: 0.5810 - val_loss: 0.0891 - val_accuracy: 0.5677\n",
      "Epoch 38/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0834 - accuracy: 0.5879 - val_loss: 0.0888 - val_accuracy: 0.5719\n",
      "Epoch 39/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0836 - accuracy: 0.5858 - val_loss: 0.0891 - val_accuracy: 0.5669\n",
      "Epoch 40/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0830 - accuracy: 0.5896 - val_loss: 0.0889 - val_accuracy: 0.5637\n",
      "Epoch 41/50\n",
      "351/351 [==============================] - 12s 35ms/step - loss: 0.0827 - accuracy: 0.5891 - val_loss: 0.0884 - val_accuracy: 0.5691\n",
      "Epoch 42/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0829 - accuracy: 0.5890 - val_loss: 0.0889 - val_accuracy: 0.5694\n",
      "Epoch 43/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0826 - accuracy: 0.5879 - val_loss: 0.0888 - val_accuracy: 0.5677\n",
      "Epoch 44/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0819 - accuracy: 0.5935 - val_loss: 0.0886 - val_accuracy: 0.5619\n",
      "Epoch 45/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0817 - accuracy: 0.5898 - val_loss: 0.0883 - val_accuracy: 0.5734\n",
      "Epoch 46/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0808 - accuracy: 0.6026 - val_loss: 0.0889 - val_accuracy: 0.5677\n",
      "Epoch 47/50\n",
      "351/351 [==============================] - 12s 35ms/step - loss: 0.0806 - accuracy: 0.5956 - val_loss: 0.0889 - val_accuracy: 0.5702\n",
      "Epoch 48/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0810 - accuracy: 0.5998 - val_loss: 0.0886 - val_accuracy: 0.5655\n",
      "Epoch 49/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0806 - accuracy: 0.5973 - val_loss: 0.0891 - val_accuracy: 0.5662\n",
      "Epoch 50/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0803 - accuracy: 0.6030 - val_loss: 0.0887 - val_accuracy: 0.5644\n"
     ]
    }
   ],
   "source": [
    "model = keras_use_embedding_model()\n",
    "\n",
    "model = keras_use_embedding_model_train(model,np.array(list(train['ABSTRACT'])),\n",
    "                                        np.array(train[TAGS]),np.array(list(val['ABSTRACT'])),np.array(val[TAGS]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on Validation Set 0.6413059757376067\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob =  model.predict(np.array(list(val['ABSTRACT'])))\n",
    "best_thresholds = get_cut_offthreshold(y_pred_prob,val,TAGS)\n",
    "y_pred = get_predictions(y_pred_prob,best_thresholds,TAGS)\n",
    "\n",
    "print(\"F1 Score on Validation Set\", f1_score(val[TAGS], y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on Test\n",
    "\n",
    "y_pred_test_prob = model.predict(np.array(list(test_data['ABSTRACT'])))\n",
    "\n",
    "predictions = get_predictions(y_pred_test_prob,best_thresholds,TAGS)\n",
    "\n",
    "result = pd.DataFrame(predictions)\n",
    "result.columns = TAGS\n",
    "result['id'] = test_data['id']\n",
    "result.to_csv(\"universal_sent_encoder_keras.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal Sentence Embedding with Keras with topic columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import concatenate, Dense, Input, Dropout,Concatenate\n",
    "\n",
    "def keras_use_embedding_model():\n",
    "    '''\n",
    "    Use universal sentence encoder in the embedding layer of a Keras model along wiht topic columns\n",
    "    '''\n",
    "    embedding = TF_MODULE_URL\n",
    "    input_words = Input(shape=[],dtype=tf.string)\n",
    "    hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "                               dtype=tf.string, trainable=False)\n",
    "    out_emb = hub_layer(input_words)\n",
    "    tc = Input(shape=(4,))\n",
    "    tc_dense = Dense(4,)(tc)\n",
    "    cc = Concatenate(axis=1)([out_emb,tc_dense])\n",
    "    model = Dense(100, activation='relu')(cc)\n",
    "    model = Dropout(0.5)(model)\n",
    "    output = Dense(25,activation='sigmoid')(model)\n",
    "    model = Model(inputs=[input_words,tc],outputs=output)\n",
    "    print(model.summary())\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "        optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def keras_use_embedding_model_train(keras_model,train_sents,train_topic_cols,train_labels,\n",
    "                                    test_sents,test_topic_cols,test_labels):\n",
    "    '''\n",
    "    Train the keras models. Change parameters here if needed\n",
    "    '''\n",
    "    n_epochs = 50\n",
    "    n_batch_size = 32\n",
    "    # session = tf.Session()\n",
    "    # tf.keras.backend.set_session(session)\n",
    "    # session.run(tf.global_variables_initializer())\n",
    "    # session.run(tf.tables_initializer())\n",
    "    history = keras_model.fit([train_sents,train_topic_cols],\n",
    "            train_labels,\n",
    "            validation_data=([test_sents,test_topic_cols], test_labels),\n",
    "            epochs=n_epochs,\n",
    "            batch_size=n_batch_size)\n",
    "    return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        (None, 512)          256797824   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4)            20          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 516)          0           keras_layer[0][0]                \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          51700       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 25)           2525        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 256,852,069\n",
      "Trainable params: 54,245\n",
      "Non-trainable params: 256,797,824\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "351/351 [==============================] - 13s 38ms/step - loss: 0.2196 - accuracy: 0.2078 - val_loss: 0.1378 - val_accuracy: 0.3488\n",
      "Epoch 2/50\n",
      "351/351 [==============================] - 13s 36ms/step - loss: 0.1326 - accuracy: 0.3853 - val_loss: 0.1061 - val_accuracy: 0.5248\n",
      "Epoch 3/50\n",
      "351/351 [==============================] - 13s 36ms/step - loss: 0.1103 - accuracy: 0.4643 - val_loss: 0.0922 - val_accuracy: 0.5641\n",
      "Epoch 4/50\n",
      "351/351 [==============================] - 13s 36ms/step - loss: 0.0998 - accuracy: 0.5200 - val_loss: 0.0855 - val_accuracy: 0.5926\n",
      "Epoch 5/50\n",
      "351/351 [==============================] - 13s 36ms/step - loss: 0.0929 - accuracy: 0.5428 - val_loss: 0.0807 - val_accuracy: 0.5987\n",
      "Epoch 6/50\n",
      "351/351 [==============================] - 13s 36ms/step - loss: 0.0886 - accuracy: 0.5587 - val_loss: 0.0781 - val_accuracy: 0.6126\n",
      "Epoch 7/50\n",
      "351/351 [==============================] - 13s 36ms/step - loss: 0.0855 - accuracy: 0.5726 - val_loss: 0.0759 - val_accuracy: 0.6176\n",
      "Epoch 8/50\n",
      "351/351 [==============================] - 13s 36ms/step - loss: 0.0827 - accuracy: 0.5783 - val_loss: 0.0745 - val_accuracy: 0.6098\n",
      "Epoch 9/50\n",
      "351/351 [==============================] - 13s 36ms/step - loss: 0.0809 - accuracy: 0.5924 - val_loss: 0.0730 - val_accuracy: 0.6255\n",
      "Epoch 10/50\n",
      "351/351 [==============================] - 13s 36ms/step - loss: 0.0792 - accuracy: 0.5963 - val_loss: 0.0724 - val_accuracy: 0.6173\n",
      "Epoch 11/50\n",
      "351/351 [==============================] - 13s 36ms/step - loss: 0.0784 - accuracy: 0.5978 - val_loss: 0.0717 - val_accuracy: 0.6251\n",
      "Epoch 12/50\n",
      "351/351 [==============================] - 13s 37ms/step - loss: 0.0765 - accuracy: 0.6067 - val_loss: 0.0711 - val_accuracy: 0.6326\n",
      "Epoch 13/50\n",
      "351/351 [==============================] - 14s 39ms/step - loss: 0.0756 - accuracy: 0.6078 - val_loss: 0.0704 - val_accuracy: 0.6230\n",
      "Epoch 14/50\n",
      "351/351 [==============================] - 13s 36ms/step - loss: 0.0747 - accuracy: 0.6073 - val_loss: 0.0699 - val_accuracy: 0.6316\n",
      "Epoch 15/50\n",
      "351/351 [==============================] - 13s 37ms/step - loss: 0.0735 - accuracy: 0.6152 - val_loss: 0.0695 - val_accuracy: 0.6191\n",
      "Epoch 16/50\n",
      "351/351 [==============================] - 12s 35ms/step - loss: 0.0732 - accuracy: 0.6154 - val_loss: 0.0693 - val_accuracy: 0.6280\n",
      "Epoch 17/50\n",
      "351/351 [==============================] - 13s 36ms/step - loss: 0.0727 - accuracy: 0.6205 - val_loss: 0.0689 - val_accuracy: 0.6287\n",
      "Epoch 18/50\n",
      "351/351 [==============================] - 12s 36ms/step - loss: 0.0715 - accuracy: 0.6191 - val_loss: 0.0686 - val_accuracy: 0.6223\n",
      "Epoch 19/50\n",
      "351/351 [==============================] - 13s 36ms/step - loss: 0.0708 - accuracy: 0.6215 - val_loss: 0.0690 - val_accuracy: 0.6323\n",
      "Epoch 20/50\n",
      "351/351 [==============================] - 13s 37ms/step - loss: 0.0705 - accuracy: 0.6247 - val_loss: 0.0682 - val_accuracy: 0.6333\n",
      "Epoch 21/50\n",
      "351/351 [==============================] - 12s 36ms/step - loss: 0.0701 - accuracy: 0.6224 - val_loss: 0.0682 - val_accuracy: 0.6266\n",
      "Epoch 22/50\n",
      "351/351 [==============================] - 12s 35ms/step - loss: 0.0691 - accuracy: 0.6272 - val_loss: 0.0681 - val_accuracy: 0.6355\n",
      "Epoch 23/50\n",
      "351/351 [==============================] - 12s 35ms/step - loss: 0.0689 - accuracy: 0.6287 - val_loss: 0.0682 - val_accuracy: 0.6348\n",
      "Epoch 24/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0685 - accuracy: 0.6246 - val_loss: 0.0681 - val_accuracy: 0.6294\n",
      "Epoch 25/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0681 - accuracy: 0.6310 - val_loss: 0.0678 - val_accuracy: 0.6373\n",
      "Epoch 26/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0674 - accuracy: 0.6345 - val_loss: 0.0676 - val_accuracy: 0.6330\n",
      "Epoch 27/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0671 - accuracy: 0.6313 - val_loss: 0.0674 - val_accuracy: 0.6333\n",
      "Epoch 28/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0663 - accuracy: 0.6403 - val_loss: 0.0676 - val_accuracy: 0.6341\n",
      "Epoch 29/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0661 - accuracy: 0.6373 - val_loss: 0.0675 - val_accuracy: 0.6408\n",
      "Epoch 30/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0661 - accuracy: 0.6401 - val_loss: 0.0674 - val_accuracy: 0.6333\n",
      "Epoch 31/50\n",
      "351/351 [==============================] - 12s 35ms/step - loss: 0.0659 - accuracy: 0.6406 - val_loss: 0.0677 - val_accuracy: 0.6298\n",
      "Epoch 32/50\n",
      "351/351 [==============================] - 12s 35ms/step - loss: 0.0655 - accuracy: 0.6432 - val_loss: 0.0674 - val_accuracy: 0.6316\n",
      "Epoch 33/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0648 - accuracy: 0.6448 - val_loss: 0.0670 - val_accuracy: 0.6376\n",
      "Epoch 34/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0646 - accuracy: 0.6440 - val_loss: 0.0672 - val_accuracy: 0.6358\n",
      "Epoch 35/50\n",
      "351/351 [==============================] - 12s 35ms/step - loss: 0.0646 - accuracy: 0.6413 - val_loss: 0.0671 - val_accuracy: 0.6337\n",
      "Epoch 36/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0643 - accuracy: 0.6463 - val_loss: 0.0671 - val_accuracy: 0.6401\n",
      "Epoch 37/50\n",
      "351/351 [==============================] - 12s 35ms/step - loss: 0.0636 - accuracy: 0.6487 - val_loss: 0.0674 - val_accuracy: 0.6376\n",
      "Epoch 38/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0634 - accuracy: 0.6497 - val_loss: 0.0673 - val_accuracy: 0.6308\n",
      "Epoch 39/50\n",
      "351/351 [==============================] - 12s 35ms/step - loss: 0.0628 - accuracy: 0.6484 - val_loss: 0.0672 - val_accuracy: 0.6358\n",
      "Epoch 40/50\n",
      "351/351 [==============================] - 12s 35ms/step - loss: 0.0622 - accuracy: 0.6565 - val_loss: 0.0673 - val_accuracy: 0.6312\n",
      "Epoch 41/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0620 - accuracy: 0.6515 - val_loss: 0.0672 - val_accuracy: 0.6330\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0621 - accuracy: 0.6470 - val_loss: 0.0670 - val_accuracy: 0.6358\n",
      "Epoch 43/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0623 - accuracy: 0.6488 - val_loss: 0.0673 - val_accuracy: 0.6358\n",
      "Epoch 44/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0614 - accuracy: 0.6532 - val_loss: 0.0672 - val_accuracy: 0.6305\n",
      "Epoch 45/50\n",
      "351/351 [==============================] - 12s 35ms/step - loss: 0.0613 - accuracy: 0.6562 - val_loss: 0.0673 - val_accuracy: 0.6333\n",
      "Epoch 46/50\n",
      "351/351 [==============================] - 12s 35ms/step - loss: 0.0611 - accuracy: 0.6544 - val_loss: 0.0673 - val_accuracy: 0.6344\n",
      "Epoch 47/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0605 - accuracy: 0.6582 - val_loss: 0.0674 - val_accuracy: 0.6348\n",
      "Epoch 48/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0608 - accuracy: 0.6609 - val_loss: 0.0677 - val_accuracy: 0.6362\n",
      "Epoch 49/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0607 - accuracy: 0.6558 - val_loss: 0.0676 - val_accuracy: 0.6369\n",
      "Epoch 50/50\n",
      "351/351 [==============================] - 12s 34ms/step - loss: 0.0601 - accuracy: 0.6581 - val_loss: 0.0681 - val_accuracy: 0.6344\n"
     ]
    }
   ],
   "source": [
    "model = keras_use_embedding_model()\n",
    "\n",
    "train_topic_cols = np.array(train[TOPIC_COLS])\n",
    "val_topic_cols = np.array(val[TOPIC_COLS])\n",
    "train_labels = np.array(train[TAGS])\n",
    "val_labels = np.array(val[TAGS])\n",
    "\n",
    "model = keras_use_embedding_model_train(model,np.array(list(train['ABSTRACT'])),train_topic_cols,train_labels,np.array(list(val['ABSTRACT'])),val_topic_cols,val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on Validation Set 0.7207574654042243\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob =  model.predict([np.array(list(val['ABSTRACT'])),val_topic_cols])\n",
    "best_thresholds = get_cut_offthreshold(y_pred_prob,val,TAGS)\n",
    "y_pred = get_predictions(y_pred_prob,best_thresholds,TAGS)\n",
    "\n",
    "print(\"F1 Score on Validation Set\", f1_score(val[TAGS], y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on Test\n",
    "\n",
    "y_pred_test_prob = model.predict([np.array(list(test_data['ABSTRACT'])),np.array(test_data[TOPIC_COLS])])\n",
    "\n",
    "predictions = get_predictions(y_pred_test_prob,best_thresholds,TAGS)\n",
    "\n",
    "result = pd.DataFrame(predictions)\n",
    "result.columns = TAGS\n",
    "result['id'] = test_data['id']\n",
    "result.to_csv(\"universal_sent_encoder_keras_topic_cols.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
